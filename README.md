# ğŸ¦ LION SIGNAL HQ

**Find multi-bagger stocks BEFORE everyone else!**

This system automatically scrapes BSE & NSE announcements every 30 minutes, analyzes them with AI, and shows you what matters on a beautiful dashboard.

---

## ğŸ¯ What It Does

```
Every 30 minutes (24/7):
1. ğŸ” Scrapes BSE & NSE for new announcements
2. ğŸ§  Sends 20 PDF links to Gemini AI  
3. ğŸ’¾ Saves smart summaries (NOT the PDFs!)
4. ğŸ—‘ï¸ Auto-deletes data after 365 days
5. ğŸ“Š Shows everything on beautiful dashboard
```

**Cost: â‚¹0** (Gemini free tier + GitHub free)

---

## ğŸš€ SUPER SIMPLE SETUP (15 Minutes)

### Step 1: Get Gemini API Key (5 min)

1. Go to: https://aistudio.google.com/apikey
2. Click "Create API Key"
3. Copy the key (starts with `AIza...`)
4. âœ… Done!

### Step 2: Create GitHub Account (2 min)

1. Go to: https://github.com
2. Click "Sign Up"  
3. Enter email, create password
4. âœ… Done!

### Step 3: Upload Files to GitHub (5 min)

1. Click the green **"+ New"** button (top right)
2. Name it: `lion-signal-hq`
3. Click **"Create repository"**
4. Click **"uploading an existing file"** link
5. Drag ALL these files into the box:
   ```
   config.py
   scraper.py
   analyzer.py
   database.py
   main.py
   app.py
   requirements.txt
   .github/workflows/schedule.yml
   templates/dashboard.html
   ```
6. Click **"Commit changes"**
7. âœ… Done!

### Step 4: Add Your API Key (3 min)

1. In your repository, click **"Settings"** tab
2. Click **"Secrets and variables"** â†’ **"Actions"**
3. Click **"New repository secret"**
4. Name: `GEMINI_API_KEY`
5. Value: (paste your Gemini API key from Step 1)
6. Click **"Add secret"**
7. âœ… Done!

### Step 5: Start It! (1 min)

1. Click **"Actions"** tab
2. Click **"Lion Signal Scraper"** 
3. Click **"Run workflow"** button
4. Click green **"Run workflow"**
5. Wait 2 minutes
6. âœ… It's running!

---

## ğŸŒ See Your Dashboard

### Option A: Run Locally (On Your Computer)

```bash
# Install Python packages
pip install -r requirements.txt

# Run the web server
python app.py

# Open browser to: http://localhost:5000
```

### Option B: Deploy to Free Hosting

**Netlify (Easiest):**
1. Go to netlify.com
2. Click "Add new site" â†’ "Import from GitHub"
3. Select your `lion-signal-hq` repo
4. Deploy!

**Your dashboard will be live at:** `lion-signal-hq.netlify.app`

---

## ğŸ“Š What You'll See

Your dashboard shows:

```
ğŸ¦ LION SIGNAL HQ                    ğŸŒ™ Dark Mode
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” Search: [___________]  Filter: [All â–¼]

ğŸŸ¢ CONCORD BIOTECH                         BSE
   Q3 INVESTOR PRESENTATION
   Revenue growth robust, 6 APIs filed...
   ğŸ“„ READ PDF  12-Feb-2026 00:45

ğŸŸ¢ HDFC BANK                               NSE
   RBI APPROVAL - ICICI ACQUISITION
   ICICI Prudential granted 9.95% holding...
   ğŸ“„ READ PDF  12-Feb-2026 00:30
```

âœ… Light/Dark mode toggle  
âœ… Search by company  
âœ… Filter by exchange (BSE/NSE)  
âœ… Only shows LINKS (click to open PDF)  
âœ… Auto-updates every 30 min  

---

## âš™ï¸ Settings You Can Change

Edit `config.py`:

```python
RETENTION_DAYS = 365  # Change to 7, 30, 90, 365, 1000, etc.
BATCH_SIZE = 20       # PDFs per Gemini request
UPDATE_FREQUENCY_MINUTES = 30  # How often to scrape
```

---

## ğŸ› ï¸ How It Works (Behind The Scenes)

```
GitHub Actions (Free Robot)
    â†“
Every 30 minutes:
    â†“
1. scraper.py â†’ Visits BSE/NSE websites
    â†“
2. Finds new announcement PDF links
    â†“
3. analyzer.py â†’ Sends 20 links to Gemini
    â†“
4. Gemini reads PDFs and extracts:
   - Company name
   - Headline
   - Important numbers (revenue, profit, orders)
   - 2-3 line summary
    â†“
5. database.py â†’ Saves summaries
   (NOT the PDFs - just links!)
    â†“
6. Janitor â†’ Deletes anything older than 365 days
    â†“
7. app.py â†’ Shows on dashboard
    â†“
Sleeps for 30 minutes â†’ Repeats
```

---

## ğŸ“ File Structure

```
lion-signal-hq/
â”œâ”€â”€ config.py              # Settings (EDIT THIS!)
â”œâ”€â”€ scraper.py             # The scout (visits websites)
â”œâ”€â”€ analyzer.py            # The brain (Gemini AI)
â”œâ”€â”€ database.py            # The notebook (SQLite)
â”œâ”€â”€ main.py                # The conductor (runs everything)
â”œâ”€â”€ app.py                 # Web server (Flask)
â”œâ”€â”€ requirements.txt       # Python packages needed
â”œâ”€â”€ lion_signal.db         # Database (auto-created)
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ schedule.yml   # GitHub Actions (runs every 30 min)
â””â”€â”€ templates/
    â””â”€â”€ dashboard.html     # The beautiful dashboard
```

---

## â“ Troubleshooting

### "No announcements showing up"

1. Check GitHub Actions ran successfully:
   - Go to "Actions" tab
   - See if latest run is âœ… green
   
2. Check API key is set:
   - Settings â†’ Secrets â†’ GEMINI_API_KEY should exist

3. Check database file exists:
   - Look for `lion_signal.db` in your repository

### "Gemini API error"

- You might have hit the free tier limit (1000 requests/day)
- Wait 24 hours, or upgrade to paid tier ($0.30/M tokens)

### "Website not loading"

- Make sure you ran `python app.py`
- Open browser to `http://localhost:5000` (not 127.0.0.1)
- Check firewall isn't blocking port 5000

---

## ğŸ’° Costs

| Item | Cost |
|------|------|
| Gemini API (Free Tier) | â‚¹0 |
| GitHub Actions | â‚¹0 |
| GitHub Storage | â‚¹0 |
| Hosting (Netlify/Vercel) | â‚¹0 |
| **TOTAL** | **â‚¹0** |

**If you exceed free tiers:**
- Gemini: ~â‚¹500-1000/month for heavy usage
- Hosting: â‚¹300-500/month for premium

---

## ğŸ‰ You're Done!

The system is now running 24/7:
- âœ… Scraping BSE & NSE every 30 minutes
- âœ… Analyzing with AI
- âœ… Storing smart summaries
- âœ… Auto-deleting after 365 days
- âœ… Beautiful dashboard

**Find those multi-baggers!** ğŸ¦ğŸš€

---

## ğŸ“ Need Help?

- Read the code comments (they're in 5-year-old language!)
- Check GitHub Actions logs for errors
- All files are heavily commented

**Happy hunting!** ğŸ¦
